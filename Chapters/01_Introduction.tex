\chapter{Introduction}
\label{ch:introduction}

\section{Background and Context}
\label{sec:background-context}

Believable computational agents that simulate human behavior enable diverse applications: immersive virtual environments and social simulations \cite{parkGenerativeAgentsInteractive2023a}, rehearsal spaces for practicing interpersonal communication, prototyping tools for testing social scenarios, training systems for rare yet difficult social situations, and platforms for validating social science theories. By \textit{believability}, we mean the human-perceived realism of an agent's behavior: whether its actions appear consistent with its apparent goals, personality, and knowledge. Non-player characters in open-world games can navigate complex social relationships; virtual assistants and social robots can interact more naturally; cognitive models can inform human-computer interaction design. The common requirement is an architecture that produces behavior consistent with past experience, reacts believably to environmental changes, and maintains coherence over extended interactions. A formal treatment of believability is provided in \cref{ch:background}.

Large Language Model (LLM)-driven generative agents---computational software agents that simulate believable human behavior using LLMs with mechanisms for memory storage, reflection, and dynamic retrieval---can simulate complex, human-like behavior in virtual worlds, games, and social scenarios by leveraging commonsense reasoning and natural language capabilities \cite{parkGenerativeAgentsInteractive2023a}. However, purely neural approaches produce logical inconsistencies: agents attempt impossible actions (opening nonexistent doors), interact with entities that are not present (talking to agents who are elsewhere), or pursue conflicting goals, undermining believability \cite{batesRoleEmotionBelievable1994}.

Park et al.\ \cite{parkGenerativeAgentsInteractive2023a} demonstrated emergent social dynamics through memory streams, reflection, and hierarchical planning. Yet their planning component lacks mechanisms to verify logical consistency or enforce environmental constraints, producing plans that are contextually plausible but violate hard constraints or exhibit temporal inconsistencies. Throughout this thesis, we refer to the Park et al.\ work as \emph{the original paper}---the foundational architecture that we extend with symbolic planning.

Neuro-symbolic AI can address this by combining neural generation with symbolic planning \cite{tantakounLLMsPlanningModelers2025}. Rather than relying solely on the LLM's inherent reasoning, this hybrid approach builds structured \textit{scaffolding}---formal constraints, validators, and iterative refinement mechanisms---around the core intelligence of the model. As recently as December 2025, research continues to demonstrate that such scaffolding still has substantial room to grow as a key direction for improving LLM-driven systems \cite{zhang2025recursive}. By embedding symbolic validation and constraint enforcement alongside neural generation, we create an architecture in which both components complement each other: the LLM provides flexibility and commonsense reasoning, while symbolic planning ensures logical consistency and adherence to environmental constraints.

\section*{Note on the Use of AI}
\label{sec:ai-disclaimer}

AI-assisted tools, including large language models, were used during the preparation of this thesis for tasks such as literature review, code development, writing assistance, and figure generation. A detailed account of AI usage, including specific tools, tasks, and the extent of human oversight, is provided in Chapter~\ref{ch:ai-usage}.

\section{Problem Statement}
\label{sec:problem-statement}

Existing agent architectures face a fundamental tradeoff: purely symbolic systems ensure logical consistency but lack flexibility and commonsense reasoning, while purely neural LLM-driven agents offer adaptability but produce logically inconsistent plans.

\textbf{Research question:} How can a neuro-symbolic planning framework improve the coherence and believability---the human-perceived realism of agent behavior---of LLM-driven generative agents?\footnote{Formal definitions are provided in \cref{ch:background}: \emph{Large Language Models} (\cref{subsec:llm}), \emph{Agents} (\cref{def:agent}), \emph{Planning} (\cref{def:planning-problem}), \emph{Coherence} (\cref{def:coherence}), \emph{Believability} (\cref{def:believability}), and \emph{Neuro-Symbolic Systems for Planning} (\cref{subsec:neuro-symbolic}).}


\section{Research Aim and Objectives}
\label{sec:research-aim-objectives}

\textbf{Aim:} To develop and evaluate a hybrid neuro-symbolic planning system in which an LLM generates a hierarchical plan, the plan actions and environment constraints are formalized in PDDL, and a symbolic validator verifies logical consistency, identifies constraint violations, and guides iterative plan refinement. 

\textbf{Objectives:}

\begin{enumerate}
    \item Reimplement the generative agents architecture \cite{parkGenerativeAgentsInteractive2023a} with a modular, extensible codebase that supports integration of symbolic planning components.
    \item Design and implement a PDDL-based validator that formalizes environmental constraints, detects planning violations, and outputs actionable diagnostic feedback.
    \item Develop visualization and explanation tools that make agent plans, constraint violations, and repair proposals inspectable to researchers and evaluators.
    \item Evaluate the system using (a) quantitative metrics (constraint violation rates, plan success rates, and repair efficiency) comparing a baseline hierarchical planner against the neuro-symbolic approach, and (b) qualitative human evaluation of perceived believability.
\end{enumerate}


\section{Methodological Overview}
\label{sec:methodological-overview}

This study extends the generative agents architecture \cite{parkGenerativeAgentsInteractive2023a} by replacing hierarchical planning with a neuro-symbolic framework. The LLM generates hierarchical plans and PDDL action schemas; a symbolic validator detects constraint violations.
 Evaluation combines:

\begin{itemize}
    \item \textbf{Qualitative assessment}: Within-subjects user study comparing perceived believability of agent behaviors from both systems.
    \item \textbf{Quantitative metrics}: Constraint violation counts and rates on matched scenarios comparing (i) baseline hierarchical planning and (ii) neuro-symbolic planning with validator-guided revision. 
    Metrics include violations per 100 actions, plan success rates, and repair efficiency. 
\end{itemize}


\section{Scope and Limitations}
\label{sec:scope-limitations}


This project focuses on simulation environments with deterministic action effects and complete observability. Real-world robotics introduces sensing uncertainty and physical dynamics beyond our scope. Evaluation constraint adherence, and perceived believability rather than real-time performance or scalability to large multi-agent systems.


\section{Thesis Structure}
\label{sec:thesis-structure}

The remainder of the thesis is organized as follows:
\begin{itemize}
    \item \textbf{Chapter 2: Theoretical Background} --- Establishes core concepts (LLMs, agents, planning paradigms including PDDL) and reviews relevant literature.
    \item \textbf{Chapter 3: Methodology} --- Describes the system design, experimental setup, and evaluation protocols. Details the symbolic validator architecture and the within-subjects user study for assessing believability and constraint adherence.
    \item \textbf{Chapter 4: Results} --- Reports quantitative constraint-violation metrics and qualitative believability findings from the user study.
    \item \textbf{Chapter 5: Discussion} --- Interprets results, situates findings within the literature, and discusses limitations and implications for agent design. 
    \item \textbf{Chapter 6: Conclusion and Future Work} --- Summarizes contributions and suggests directions for future research.
    \item \textbf{Chapter 7: Use of AI in this Thesis} --- Declaration of AI tools used in the thesis preparation.
\end{itemize}
