\chapter{Introduction}

\section{Background and context}
Artificial intelligence has increasingly turned toward \textbf{Large Language Models (LLMs)} for generating human-like text and behaviour. When embedded in generative agents, these models can simulate complex social dynamics and interactive narratives. Despite their linguistic fluency, such agents frequently exhibit logical inconsistencies and incoherent action sequences within simulated environments.

Recent work
(for example, \cite{park2023} and \cite{zhao2023})
suggests that combining symbolic reasoning with LLMs can improve task coherence and narrative believability. This thesis focuses first on a neuro-symbolic validator, a form of symbolic scaffolding: the LLM continues to propose goals and hierarchical sketches, while a symbolic validator checks proposed plans against explicit constraints, reports violations, and suggests repairs or diagnostics.
The aim is to obtain the benefits of symbolic guarantees such as constraint enforcement, temporal checks, and explainability without initially replacing the LLM's proposal role with a planner.

\section{Problem statement}

Generative agents produce dynamic, human-like interactions, but their lack of consistent, constraint-respecting planning undermines realism. Current approaches either rely too heavily on symbolic systems, limiting flexibility, or on purely neural models, which lack logical guarantees.

	\textbf{Problem statement:} How can a neuro-symbolic scaffolding system improve the coherence and believability of LLM-driven generative agents in interactive environments?

\section{Research aim and objectives}

	\textbf{Aim:} To develop and evaluate a hybrid neuro-symbolic scaffolding system in which an LLM proposes plans and a symbolic validator verifies, critiques, and suggests repairs to those plans.

	\textbf{Objectives:}
\begin{enumerate}
\item Reimplement the original system codebase in a modular, well-documented, and extensible architecture to ease future extensions and maintenance.
\item Design a validator schema and data contract for expressing constraints, diagnostics, and suggested repairs, and implement a prototype that integrates an LLM sketching module with this symbolic validator, including tooling to surface explanations and repair proposals.
\item Improve UI and UX tooling to surface explanations, visualizations, and decision rationales so that agent decisions and plans are inspectable by researchers and evaluators.
\item Evaluate the prototype using: (a) quantitative, validator-based metrics (e.g., constraint violations per run, violation rate per 100 actions, success rate, rounds-to-zero, repair efficiency) comparing a baseline against our system after a small number of validator-guided revision rounds; and (b) human-centered evaluation (perceived believability and narrative coherence).
\end{enumerate}

\section{Methodological overview}
The study combines computational implementation with human-centered evaluation,

integrating a large language model with a symbolic validator that inspects LLM-generated plans. 
Evaluation comprises two complementary strands: (i) quantitative, validator-based evaluation that compares a GA-like baseline against our validator-augmented system on matched scenarios (e.g., counts/rates of constraint violations and simple repair indicators across a small number of revision rounds), and (ii) human-centered evaluation that measures perceived believability and narrative coherence (with brief qualitative feedback on explainability and tooling).

\section{Scope and limitations}
The project focuses on simulation environments rather than real-world robotics. Symbolic representations are limited to deterministic domains, and results primarily assess narrative consistency and social plausibility.

\section{Thesis structure}
The thesis is structured as follows:
\begin{itemize}
	\item \textbf{Chapter 2:} Theoretical background and related work.
	\item \textbf{Chapter 3:} Methodology â€” experimental setup and system design.
	\item \textbf{Chapter 4:} Implementation and Evaluation.
	\item \textbf{Chapter 5:} Results and Discussion.
	\item \textbf{Chapter 6:} Conclusion and Future Work.
\end{itemize}
