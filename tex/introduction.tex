\chapter{Introduction}

\section{Background and Context}
Artificial intelligence has increasingly turned toward \textbf{Large Language Models (LLMs)} for generating human-like text and behavior. When embedded in \textit{generative agents}, these models can simulate complex social dynamics and interactive narratives. However, despite their linguistic fluency, such agents frequently exhibit \textbf{logical inconsistencies} and \textbf{incoherent action sequences} within simulated environments.

Recent research—such as \cite{park2023} and \cite{zhao2023}—shows that combining symbolic planning with LLM reasoning can significantly improve \textbf{task coherence} and \textbf{narrative believability}.

\section{Problem Statement}
While generative agents can engage in dynamic, human-like interactions, their lack of \textbf{consistent, constraint-respecting planning} undermines realism. Current approaches either rely too heavily on symbolic systems—limiting flexibility—or on purely neural models, which lack logical guarantees.

\textbf{Problem:}  
How can a neuro-symbolic planning framework improve the coherence and believability of LLM-driven generative agents in interactive environments?

\section{Research Aim and Objectives}
\textbf{Aim:}  
To develop and evaluate a hybrid neuro-symbolic planning framework combining the reasoning power of LLMs with the formal structure of symbolic planning.

\textbf{Objectives:}
\begin{enumerate}
\item Review and categorize state-of-the-art approaches to neuro-symbolic planning and LLM-based agents.  
\item Design a framework where LLMs generate and refine \textbf{PDDL schemas}.  
\item Implement the system in an \textbf{interactive simulation environment}.  
\item Evaluate the resulting agents for logical coherence and perceived believability.  
\item Reflect on broader implications for narrative AI and multi-agent systems.
\end{enumerate}

\section{Methodological Overview}
The study will combine \textbf{computational implementation} with \textbf{human-centered evaluation}, integrating a large language model with a symbolic planner (PDDL). Evaluation metrics include both \textbf{constraint satisfaction} and \textbf{human-rated believability}.

\section{Scope and Limitations}
The project focuses on \textbf{simulation environments} rather than real-world robotics. Symbolic representations will be limited to deterministic domains, and results will primarily assess \textbf{narrative consistency} and \textbf{social plausibility}.

\section{Thesis Structure}
\begin{itemize}
\item \textbf{Chapter 2:} Related Work — overview of neuro-symbolic methods and generative agent architectures.  
\item \textbf{Chapter 3:} Methodology — experimental setup and system design.  
\item \textbf{Chapter 4:} Implementation and Evaluation.  
\item \textbf{Chapter 5:} Results and Discussion.  
\item \textbf{Chapter 6:} Conclusion and Future Work.
\end{itemize}
